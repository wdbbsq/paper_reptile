1. FedRec++: Lossless Federated Recommendation with Explicit Feedback.
https://ojs.aaai.org/index.php/AAAI/article/view/16546

Abstract
With the marriage of federated machine learning and recommender systems for privacy-aware preference modeling and personalization, there comes a new research branch called federated recommender systems aiming to build a recommendation model in a distributed way, i.e., each user is represented as a distributed client where his/her original rating data are not shared with the server or the other clients. Notice that, besides the sensitive information of a specific rating score assigned to a certain item by a user, the information of a user's rated set of items shall also be well protected. Some very recent works propose to randomly sample some unrated items for each user and then assign some virtual ratings, so that the server can not identify the scores and the set of rated items easily during the server-client interactions. However, the virtual ratings assigned to the randomly sampled items will inevitably introduce some noise to the model training process, which will then cause loss in recommendation performance. In this paper, we propose a novel lossless federated recommendation method (FedRec++) by allocating some denoising clients (i.e., users) to eliminate the noise in a privacy-aware manner. We further analyse our FedRec++ in terms of security and losslessness, and discuss its generality in the context of existing works. Extensive empirical studies clearly show the effectiveness of our FedRec++ in providing accurate and privacy-aware recommendation without much additional communication cost.

随着联邦机器学习和推荐系统的结合，隐私感知的偏好建模和个性化，出现了一个新的研究分支——联邦推荐系统，旨在以分布式的方式构建推荐模型，即:每个用户都表示为一个分布式客户机，其中他/她的原始评级数据不与服务器或其他客户机共享。请注意，除了用户为某一物品分配的特定评级分数的敏感信息外，用户的评级物品集的信息也应得到很好的保护。最近的一些工作建议为每个用户随机取样一些未评级的项目，然后分配一些虚拟评级，这样服务器就不能在服务器-客户端交互过程中轻松地识别分数和评级项目集。然而，对随机抽样的项目进行虚拟评分，不可避免地会给模型训练过程引入一些噪声，从而导致推荐性能的损失。在本文中，我们提出了一种新的无损联邦推荐方法(FedRec++)，通过分配去噪客户端(即用户)以一种隐私意识的方式去噪。我们进一步分析了我们的FedRec++在安全性和无损方面，并讨论了其在现有工作背景下的通用性。大量的实证研究清楚地表明，我们的FedRec++在提供准确和隐私意识的建议而不需要太多额外的通信成本方面的有效性。

2. Model-sharing Games: Analyzing Federated Learning Under Voluntary Participation.
https://ojs.aaai.org/index.php/AAAI/article/view/16669

Abstract
Federated learning is a setting where agents, each with access to their own data source, combine models learned from local data to create a global model. If agents are drawing their data from different distributions, though, federated learning might produce a biased global model that is not optimal for each agent. This means that agents face  a fundamental question: should they join the global model or stay with their local model? In this work, we show how this situation can be naturally analyzed through the framework of coalitional game theory. 

Motivated by these considerations, we propose the following game:  there are heterogeneous players with  different model parameters  governing their data distribution and different amounts of data they have noisily drawn from their own distribution. Each player's goal is to obtain a model with minimal expected mean squared error (MSE) on their own distribution. They have a choice of fitting a model based solely on their own data, or combining their learned parameters with those of some subset of the other players. Combining models reduces the variance component of their error through access to more data, but increases the bias because of the heterogeneity of distributions. In this work, we derive exact expected MSE values for problems in linear regression and mean estimation. We use these values to analyze the resulting game in the framework of hedonic game theory; we study how players might divide into coalitions, where each set of players within a coalition jointly constructs a single model.   In a case with arbitrarily many players that each have either a "small" or "large" amount of data, we constructively show that there always exists a stable partition of players into coalitions.  

联合学习是一种设置，每个代理都可以访问自己的数据源，将从本地数据学习到的模型组合起来，以创建一个全局模型。但是，如果代理从不同的分布中提取数据，那么联合学习可能会产生一个不适合每个代理的有偏差的全局模型。这意味着代理商面临着一个根本性的问题:他们应该加入全局模式还是保留他们的本地模式?在这项工作中，我们展示了如何通过联盟博弈理论的框架自然地分析这种情况。
基于这些考虑，我们提出了以下的游戏:不同的玩家使用不同的模型参数来控制他们的数据分布，以及他们从自己的分布中获取的不同数量的数据。每个参与者的目标是在他们自己的分布上获得一个具有最小期望均方误差(MSE)的模型。他们可以选择仅仅基于自己的数据去适应一个模型，或者将他们学到的参数与其他玩家的一些子集相结合。通过访问更多的数据，组合模型减少了误差的方差成分，但由于分布的异质性增加了偏差。在这项工作中，我们得到精确的期望MSE值的问题在线性回归和均值估计。我们用这些值在享乐博弈论的框架下分析结果博弈;我们研究参与者如何分裂成联盟，联盟中的每组参与者共同构建一个单一模型。在任意多玩家的情况下，每个玩家都有一个“小”或“大”的数据量，我们建设性地表明，总是存在一个稳定的将玩家划分为联盟的情况。

3. Provably Secure Federated Learning against Malicious Clients.
https://ojs.aaai.org/index.php/AAAI/article/view/16849

Abstract
Federated learning enables clients to collaboratively learn a shared global model without sharing their local training data with a cloud server. However, malicious clients can corrupt the  global  model  to  predict  incorrect  labels  for  testing  examples. Existing defenses against malicious clients leverage Byzantine-robust federated learning methods. However, these methods cannot provably guarantee that the predicted label for  a  testing  example  is  not  affected  by  malicious  clients. We bridge this gap via ensemble federated learning. In particular, given any base federated learning algorithm, we use the algorithm to learn multiple global models, each of which is learnt using a randomly selected subset of clients. When predicting  the  label  of  a  testing  example,  we  take  majority vote  among  the  global  models.  We  show  that  our  ensemble  federated  learning  with  any  base  federated  learning  algorithm is provably secure against malicious clients. Specifically, the label predicted by our ensemble global model for a testing example is provably not affected by a bounded number of malicious clients. Moreover, we show that our derived bound is tight. We evaluate our method on MNIST and Human Activity Recognition datasets. For instance, our method can achieve a certified accuracy of 88% on MNIST when 20 out of 1,000 clients are malicious.

联合学习使客户端能够协作学习一个共享的全局模型，而无需与云服务器共享他们的本地训练数据。然而，恶意的客户端可能会破坏全局模型，从而预测测试示例的不正确标签。现有的针对恶意客户端的防御利用了拜占庭式健壮的联邦学习方法。然而，这些方法不能证明测试示例的预测标签不受恶意客户机的影响。我们通过集成联合学习来弥补这个差距。特别是，给定任何基础联邦学习算法，我们使用该算法来学习多个全局模型，每个全局模型都是使用随机选择的客户子集学习的。当预测测试示例的标签时，我们在全局模型中采用多数投票。我们证明了我们的集成联邦学习与任何基础联邦学习算法对于恶意客户端是安全的。具体来说，我们的集成全局模型预测的测试示例的标签可以证明不受有限数量的恶意客户机的影响。此外，我们证明了导出的界是紧的。我们评估了我们的方法在MNIST和人类活动识别数据集。例如，当1000个客户中有20个是恶意用户时，我们的方法在MNIST上可以达到88%的认证准确率。

4. On the Convergence of Communication-Efficient Local SGD for Federated Learning.
https://ojs.aaai.org/index.php/AAAI/article/view/16920
提出了一种新的通信效率高的分布式SGD方法，通过误码补偿双压缩机制显著降低通信成本

Abstract
Federated Learning (FL) has attracted increasing attention in recent years. A leading training algorithm in FL is local SGD, which updates the model parameter on each worker and averages model parameters across different workers only once in a while. Although it has fewer communication rounds than the classical parallel SGD, local SGD still has large communication overhead in each communication round for large machine learning models, such as deep neural networks.  To address this issue, we propose a new communication-efficient distributed SGD method,  which can significantly reduce the communication cost by the error-compensated double compression mechanism. Under the non-convex setting, our theoretical results show that our approach has better communication complexity than existing  methods and enjoys the same linear speedup regarding the number of workers as the full-precision local SGD.  Moreover, we  propose a communication-efficient distributed SGD with momentum, which also has better communication complexity than existing methods and enjoys a linear speedup with respect to the number of workers.  At last, extensive experiments are conducted to verify the performance of our proposed two methods. Moreover, we  propose a communication-efficient distributed SGD with momentum to accelerate the convergence, which also has better communication complexity than existing methods and enjoys a linear speedup with respect to the number of workers.  At last, extensive experiments are conducted to verify the performance of our proposed methods.

联邦学习近年来受到越来越多的关注。FL中一个领先的训练算法是局部SGD，它更新每个工人的模型参数，并仅在一段时间内平均不同工人的模型参数。虽然与经典并行SGD相比，局部SGD的通信轮数较少，但对于深度神经网络等大型机器学习模型，局部SGD在每个通信轮中仍有较大的通信开销。为了解决这一问题，我们提出了一种新的通信效率高的分布式SGD方法，该方法通过误码补偿双压缩机制可以显著降低通信成本。在非凸设置下，我们的理论结果表明，我们的方法比现有的方法具有更好的通信复杂度，并具有与全精度局部SGD相同的工人数的线性加速。此外，我们提出了一种具有动量的通信效率的分布式SGD，它比现有的方法具有更好的通信复杂度，并且相对于worker的数量具有线性加速。最后，通过大量的实验验证了所提出的两种方法的性能。此外，我们还提出了一种具有动量的通信效率的分布式SGD来加速收敛，该方法具有比现有方法更好的通信复杂度，并且相对于worker数量具有线性加速。最后，进行了大量的实验来验证我们提出的方法的性能。

5. Personalized Cross-Silo Federated Learning on Non-IID Data.
https://ojs.aaai.org/index.php/AAAI/article/view/16960

Abstract
Non-IID data present a tough challenge for federated learning. In this paper, we explore a novel idea of facilitating pairwise collaborations between clients with similar data. We propose FedAMP, a new method employing federated attentive message passing to facilitate similar clients to collaborate more. We establish the convergence of FedAMP for both convex and non-convex models, and propose a heuristic method to further improve the performance of FedAMP when clients adopt deep neural networks as personalized models. Our extensive experiments on benchmark data sets demonstrate the superior performance of the proposed methods.

非iid数据对联邦学习提出了一个严峻的挑战。在这篇论文中，我们探索了一个新颖的想法，以促进具有相似数据的客户之间的成对协作。我们提出了一种利用联合注意消息传递的新方法FedAMP，以促进类似客户端的更多协作。我们建立了非凸模型和凸模型的FedAMP的收敛性，并提出了一种启发式方法，以进一步提高客户端采用深度神经网络作为个性化模型时FedAMP的性能。我们在基准数据集上的大量实验证明了所提方法的优越性能。

6. FLAME: Differentially Private Federated Learning in the Shuffle Model.
https://ojs.aaai.org/index.php/AAAI/article/view/17053

Abstract
Federated Learning (FL) is a promising machine learning paradigm that enables the analyzer to train a model without collecting users' raw data. To ensure users' privacy, differentially private federated learning has been intensively studied. The existing works are mainly based on the curator model or local model of differential privacy. However, both of them have pros and cons. The curator model allows greater accuracy but requires a trusted analyzer.  In the local model where users randomize local data before sending them to the analyzer, a trusted analyzer is not required but the accuracy is limited. In this work, by leveraging the \textit{privacy amplification} effect in the recently proposed shuffle model of differential privacy, we achieve the best of two worlds, i.e., accuracy in the curator model and strong privacy without relying on any trusted party. We first propose an FL framework in the shuffle model and a simple protocol (SS-Simple) extended from existing work. We find that SS-Simple only provides an insufficient privacy amplification effect in FL since the dimension of the model parameter is quite large. To solve this challenge, we propose an enhanced protocol (SS-Double) to increase the privacy amplification effect by subsampling. Furthermore, for boosting the utility when the model size is greater than the user population, we propose an advanced protocol (SS-Topk) with gradient sparsification techniques. We also provide theoretical analysis and numerical evaluations of the privacy amplification of the proposed protocols. Experiments on real-world dataset validate that SS-Topk improves the testing accuracy by 60.7% than the local model based FL. We highlight an observation that SS-Topk improves the accuracy by 33.94\% than the curator model based FL without any trusted party. Compared with non-private FL, our protocol SS-Topk only lose 1.48% accuracy under (2.348, 5e-6)-DP per epoch.

联邦学习(FL)是一种很有前途的机器学习范式，它使分析人员能够在不收集用户原始数据的情况下训练模型。为了保证用户的隐私，差异化私有联合学习被广泛研究。现有的作品主要是基于策展人模式或差异化隐私的局部模式。但是，它们都有各自的优点和缺点。管理员模型允许更高的准确性，但需要一个可信的分析器。在本地模型中，用户在将本地数据随机发送给分析器之前，不需要一个可信的分析器，但精度是有限的。在这项工作中，通过利用最近提出的差分隐私洗牌模型中的隐私放大效应，我们实现了两个世界的最佳效果，即管理员模型的准确性和不依赖任何可信方的强隐私。我们首先在shuffle模型中提出了一个FL框架，并在现有工作的基础上扩展了一个简单协议(SS-Simple)。我们发现，由于模型参数的维数较大，SS-Simple在FL中只能提供不充分的隐私放大效应。为了解决这一难题，我们提出了一种增强协议(SS-Double)，通过子采样来增加隐私放大效应。此外，为了提高模型尺寸大于用户数量时的有效性，我们提出了一种采用梯度稀疏化技术的高级协议(SS-Topk)。我们也提供了理论分析和数字评估的隐私放大的提议协议。在真实数据集上的实验表明，SS-Topk比基于FL的局部模型的测试精度提高了60.7%，比基于FL的管理员模型的测试精度提高了33.94\%。与非私有FL相比，我们的协议SS-Topk在(2.348,5e-6)-DP每个epoch下仅丢失1.48%的准确性。

7. Game of Gradients: Mitigating Irrelevant Clients in Federated Learning.
https://ojs.aaai.org/index.php/AAAI/article/view/17093

Abstract
The paradigm of Federated learning (FL) deals with multiple clients participating in collaborative training of a machine learning model under the orchestration of a central server. In this setup, each client’s data is private to itself and is not transferable to other clients or the server. Though FL paradigm has received significant interest recently from the research community, the problem of selecting the relevant clients w.r.t. the central server's learning objective is under-explored. We refer to these problems as Federated Relevant Client Selection (FRCS). Because the server doesn't have explicit control over the nature of data possessed by each client, the problem of selecting relevant clients is significantly complex in FL settings.

In this paper, we resolve important and related FRCS problems viz., selecting clients with relevant data, detecting clients that possess data relevant to a particular target label, and rectifying corrupted data samples of individual clients. We follow a principled approach to address the above FRCS problems and develop a new federated learning method using the Shapley value concept from cooperative game theory. Towards this end, we propose a cooperative game involving the gradients shared by the clients. Using this game, we compute Shapley values of clients and then present Shapley value based Federated Averaging (S-FedAvg) algorithm that empowers the server to select relevant clients with high probability. S-FedAvg turns out to be critical in designing specific algorithms to address the FRCS problems. We finally conduct a thorough empirical analysis on image classification and speech recognition tasks to show the superior performance of S-FedAvg than the baselines in the context of supervised federated learning settings.
				
联邦学习(FL)范式处理在中央服务器的协调下，多个客户机参与机器学习模型的协作训练。在这种设置中，每个客户机的数据都是私有的，不能向其他客户机或服务器传输。尽管FL范式最近受到了研究界的极大关注，但选择相关客户的问题与中央服务器的学习目标之间的关系还没有得到充分的探讨。我们将这些问题称为联邦相关客户端选择(federatedrelevant Client Selection, FRCS)。由于服务器对每个客户机拥有的数据的性质没有明确的控制，因此在FL设置中选择相关客户机的问题非常复杂。
在本文中，我们解决了重要的和相关的FRCS问题，即选择具有相关数据的客户端，检测拥有特定目标标签相关数据的客户端，以及纠正单个客户端的损坏数据样本。我们遵循一种有原则的方法来解决上述的FRCS问题，并利用合作博弈论中的Shapley值概念开发了一种新的联合学习方法。为此，我们提出了一个由客户共享梯度的合作博弈。利用这个博弈，我们计算客户端的Shapley值，然后给出基于Shapley值的联邦平均(S-FedAvg)算法，该算法赋予服务器以高概率选择相关客户端的能力。S-FedAvg在设计解决FRCS问题的特定算法方面是至关重要的。最后，我们对图像分类和语音识别任务进行了深入的实证分析，以显示S-FedAvg在监督联邦学习背景下的性能优于基线。

8. Defending against Backdoors in Federated Learning with Robust Learning Rate.
https://ojs.aaai.org/index.php/AAAI/article/view/17118

Abstract
Federated learning (FL) allows a set of agents to collaboratively train a model without sharing their potentially sensitive data. This makes FL suitable for privacy-preserving applications. At the same time, FL is susceptible to adversarial attacks due to decentralized and unvetted data. One important line of attacks against FL is the backdoor attacks. In a backdoor attack, an adversary tries to embed a backdoor functionality to the model during training that can later be activated to cause a desired misclassification. To prevent backdoor attacks, we propose a lightweight defense that requires minimal change to the FL protocol. At a high level, our defense is based on carefully adjusting the aggregation server's learning rate, per dimension and per round, based on the sign information of agents' updates. We first conjecture the necessary steps to carry a successful backdoor attack in FL setting, and then, explicitly formulate the defense based on our conjecture. Through experiments, we provide empirical evidence that supports our conjecture, and we test our defense against backdoor attacks under different settings. We observe that either backdoor is completely eliminated, or its accuracy is significantly reduced. Overall, our experiments suggest that our defense significantly outperforms some of the recently proposed defenses in the literature. We achieve this by having minimal influence over the accuracy of the trained models. In addition, we also provide convergence rate analysis for our proposed scheme.
				
联合学习(FL)允许一组代理协作训练模型，而不共享其潜在的敏感数据。这使得FL适合于保护隐私的应用程序。同时，由于数据分散且未公开，FL容易受到对抗性攻击。攻击FL的一条重要路线是后门攻击。在后门攻击中，对手试图在训练期间将后门功能嵌入到模型中，这些功能稍后会被激活，从而导致预期的错误分类。为了防止后门攻击，我们提出了一个轻量级的防御，只需对FL协议进行最小的更改。在高水平上，我们的防御是基于仔细调整聚合服务器的学习速率，每维和每轮，基于代理更新的符号信息。我们首先推测在FL设置中进行成功后门攻击的必要步骤，然后根据我们的推测明确制定防御。通过实验，我们提供了支持我们猜想的经验证据，并测试了我们在不同设置下对后门攻击的防御能力。我们观察到，要么后门被完全消除，要么它的准确性显著降低。总的来说，我们的实验表明，我们的防御明显优于文献中最近提出的一些防御。我们通过对训练模型的准确性施加最小的影响来实现这一点。此外，我们也提供了我们所提出的方案的收敛速度分析。

9. Federated Multi-Armed Bandits.
https://ojs.aaai.org/index.php/AAAI/article/view/17156

Abstract
Federated multi-armed bandits (FMAB) is a new bandit paradigm that parallels the federated learning (FL) framework in supervised learning. It is inspired by practical applications in cognitive radio and recommender systems, and enjoys features that are analogous to FL. This paper proposes a general framework of FMAB and then studies two specific federated bandit models. We first study the approximate model where the heterogeneous local models are random realizations of the global model from an unknown distribution. This model introduces a new uncertainty of client sampling, as the global model may not be reliably learned even if the finite local models are perfectly known. Furthermore, this uncertainty cannot be quantified a priori without knowledge of the suboptimality gap. We solve the approximate model by proposing Federated Double UCB (Fed2-UCB), which constructs a novel “double UCB” principle accounting for uncertainties from both arm and client sampling. We show that gradually admitting new clients is critical in achieving an O(log(T)) regret while explicitly considering the communication loss. The exact model, where the global bandit model is the exact average of heterogeneous local models, is then studied as a special case. We show that, somewhat surprisingly, the order-optimal regret can be achieved independent of the number of clients with a careful choice of the update periodicity. Experiments using both synthetic and real-world datasets corroborate the theoretical analysis and demonstrate the effectiveness and efficiency of the proposed algorithms.
				
联邦多臂盗匪(FMAB)是一种新的盗匪范式，它与联邦学习框架并行，在监督学习中得到应用。本文提出了FMAB的一般框架，并在此基础上研究了两个具体的联邦强盗模型。我们首先研究了一个近似模型，其中的异构局部模型是全局模型从一个未知分布的随机实现。该模型引入了一个新的客户抽样的不确定性，因为即使有限的局部模型是完全已知的，全局模型也可能不可靠地学习。此外，如果不了解次优性差距，这种不确定性就无法先验量化。我们通过提出联邦双UCB (federaldouble UCB)来求解近似模型，它构造了一种新的“双UCB”原理，考虑了手臂和客户取样的不确定性。我们表明，在明确考虑沟通损失的同时，逐渐承认新客户是实现O(log(T))后悔的关键。作为一种特殊情况，研究了全局强盗模型是异构局部模型的精确平均的精确模型。我们表明，有点令人惊讶的是，通过谨慎地选择更新周期，可以实现与客户端数量无关的顺序最优遗憾。使用合成和真实数据集的实验证实了理论分析，并证明了所提算法的有效性和效率。

10. Addressing Class Imbalance in Federated Learning.
https://ojs.aaai.org/index.php/AAAI/article/view/17219
设计了一个新的损失函数- Ratio loss来减轻数据不平衡的影响

Abstract
Federated learning (FL) is a promising approach for training decentralized data located on local client devices while improving efficiency and privacy. However, the distribution and quantity of the training data on the clients' side may lead to significant challenges such as class imbalance and non-IID (non-independent and identically distributed) data, which could greatly impact the performance of the common model. While much effort has been devoted to helping FL models converge when encountering non-IID data, the imbalance issue has not been sufficiently addressed. In particular, as FL training is executed by exchanging gradients in an encrypted form, the training data is not completely observable to either clients or server, and previous methods for class imbalance do not perform well for FL. Therefore, it is crucial to design new methods for detecting class imbalance in FL and mitigating its impact. In this work, we propose a monitoring scheme that can infer the composition of training data for each FL round, and design a new loss function -- Ratio Loss to mitigate the impact of the imbalance. Our experiments demonstrate the importance of acknowledging class imbalance and taking measures as early as possible in FL training, and the effectiveness of our method in mitigating the impact. Our method is shown to significantly outperform previous methods, while maintaining client privacy.
				
联邦学习(FL)是一种很有前途的方法，可以训练位于本地客户端设备上的分散数据，同时提高效率和隐私。然而，客户端训练数据的分布和数量可能会导致类不平衡和非iid(非独立同分布)数据等重大挑战，这将极大地影响通用模型的性能。虽然人们花了很多精力来帮助FL模型在遇到非iid数据时收敛，但不平衡问题还没有得到充分的解决。特别是,FL培训执行以加密的形式,通过交换梯度训练数据不完全可观测的客户或服务器,和之前的方法类失衡表现不佳的FL。因此,它是至关重要的设计新方法检测类失衡FL和减轻其影响。在这项工作中，我们提出了一个监测方案，可以推断出每个FL轮的训练数据的组成，并设计了一个新的损失函数- Ratio loss来减轻不平衡的影响。我们的实验证明了在FL训练中承认班级不平衡和尽早采取措施的重要性，以及我们的方法在减轻影响方面的有效性。我们的方法在维护客户隐私的同时，显著优于以前的方法。

11. Federated Block Coordinate Descent Scheme for Learning Global and Personalized Models.
https://ojs.aaai.org/index.php/AAAI/article/view/17240

Abstract
In federated learning, models are learned from users’ data that are held private in their edge devices, by aggregating them in the service provider’s “cloud” to obtain a global model. Such global model is of great commercial value in, e.g., improving the customers’ experience. In this paper we focus on two possible areas of improvement of the state of the art. First, we take the difference between user habits into account and propose a quadratic penalty-based formulation, for efficient learning of the global model that allows to personalize local models. Second, we address the latency issue associated with the heterogeneous training time on edge devices, by exploiting a hierarchical structure modeling communication not only between the cloud and edge devices, but also within the cloud. Specifically, we devise a tailored block coordinate descent-based computation scheme, accompanied with communication protocols for both the synchronous and asynchronous cloud settings. We characterize the theoretical convergence rate of the algorithm, and provide a variant that performs empirically better. We also prove that the asynchronous protocol, inspired by multi-agent consensus technique, has the potential for large gains in latency compared to a synchronous setting when the edge-device updates are intermittent. Finally, experimental results are provided that corroborate not only the theory, but also show that the system leads to faster convergence for personalized models on the edge devices, compared to the state of the art.
				
在联合学习中，通过将用户的数据聚合到服务提供商的“云”中，从而获得一个全局模型，从用户边缘设备中私有的数据中学习模型。这种全球化的模式在提升客户体验等方面具有很大的商业价值。在这篇论文中，我们集中在两个可能的领域改进的现状。首先，我们考虑到用户习惯之间的差异，并提出了一个基于二次惩罚的公式，以有效地学习全局模型，允许个性化局部模型。其次，我们解决了与边缘设备的异构训练时间相关的延迟问题，方法是利用分层结构对云与边缘设备之间以及云内部的通信进行建模。具体来说，我们设计了一个定制的基于块坐标下降的计算方案，并提供了同步和异步云设置的通信协议。我们描述了算法的理论收敛速度，并提供了一个在经验上表现得更好的变体。我们还证明，当边缘设备的更新是间歇性的时，与同步设置相比，受多代理共识技术启发的异步协议在延迟方面有很大的潜力。最后，实验结果不仅证实了理论，而且表明，与目前的技术相比，该系统在边缘设备上具有更快的收敛速度。

12. Toward Understanding the Influence of Individual Clients in Federated Learning.
https://ojs.aaai.org/index.php/AAAI/article/view/17263

Abstract
Federated learning allows mobile clients to jointly train a global model without sending their private data to a central server. Extensive works have studied the performance guarantee of the global model, however, it is still unclear how each individual client influences the collaborative training process. In this work, we defined a new notion, called {\em Fed-Influence}, to quantify this influence over the model parameters, and proposed an effective and efficient algorithm to estimate this metric. In particular, our design satisfies several desirable properties: (1) it requires neither retraining nor retracing, adding only linear computational overhead to clients and the server; (2) it strictly maintains the tenets of federated learning, without revealing any client's local private data; and (3) it works well on both convex and non-convex loss functions, and does not require the final model to be optimal. Empirical results on a synthetic dataset and the FEMNIST dataset demonstrate that our estimation method can approximate Fed-Influence with small bias. Further, we show an application of Fed-Influence in model debugging.
				
联合学习允许移动客户端联合训练一个全局模型，而无需将他们的私人数据发送到中央服务器。对于全局模型的性能保证进行了大量的研究，但是对于每个个体的客户端如何影响协同训练过程还不清楚。在这项工作中，我们定义了一个新的概念，称为{Fed-Influence}，以量化这种对模型参数的影响，并提出了一个有效和高效的算法来估计这个度量。特别地，我们的设计满足了几个理想的特性:(1)它不需要再培训或回溯，只增加了客户端和服务器的线性计算开销;(2)严格维护联邦学习的原则，不泄露任何客户端的本地私有数据;(3)该方法对凸和非凸损失函数都有很好的效果，且不要求最终模型是最优的。在合成数据集和FEMNIST数据集上的实验结果表明，我们的估计方法可以在较小的偏差下近似Fed-Influence。此外，我们展示了美联储影响在模型调试中的应用。

13. Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning.
https://ojs.aaai.org/index.php/AAAI/article/view/17291

Abstract
Data heterogeneity has been identified as one of the key features in federated learning but often overlooked in the lens of robustness to adversarial attacks. This paper focuses on characterizing and understanding its impact on backdooring attacks in federated learning through comprehensive experiments using synthetic and the LEAF benchmarks. The initial impression driven by our experimental results suggests that data heterogeneity is the dominant factor in the effectiveness of attacks and it may be a redemption for defending against backdooring as it makes the attack less efficient, more challenging to design effective attack strategies, and the attack result also becomes less predictable. However, with further investigations, we found data heterogeneity is more of a curse than a redemption as the attack effectiveness can be significantly boosted by simply adjusting the client-side backdooring timing. More importantly, data heterogeneity may result in overfitting at the local training of benign clients, which can be utilized by attackers to disguise themselves and fool skewed-feature based defenses. In addition, effective attack strategies can be made by adjusting attack data distribution. Finally, we discuss the potential directions of defending the curses brought by data heterogeneity. The results and lessons learned from our extensive experiments and analysis offer new insights for designing robust federated learning methods and systems.
				
数据异构性被认为是联合学习的关键特性之一，但在对抗攻击的鲁棒性方面经常被忽视。本文的重点是通过使用synthetic和LEAF基准的综合实验来描述和理解它对联邦学习中的后门攻击的影响。实验结果的初步印象表明，数据异质性是影响攻击有效性的主要因素，这可能是防范后门攻击的一种救赎，因为它使攻击效率降低，设计有效的攻击策略更具挑战性。攻击的结果也变得难以预测。然而，通过进一步的研究，我们发现数据异构与其说是一种救赎，不如说是一种诅咒，因为只要简单地调整客户端后门时机，攻击效率就可以显著提高。更重要的是，数据的异构性可能导致良性客户端的局部训练过度拟合，这可能被攻击者利用来伪装自己和欺骗基于倾斜特征的防御。此外，通过调整攻击数据分布，可以制定有效的攻击策略。最后，我们讨论了防范数据异构带来的弊端的潜在方向。我们从大量实验和分析中获得的结果和教训为设计健壮的联邦学习方法和系统提供了新的见解。

14. Secure Bilevel Asynchronous Vertical Federated Learning with Backward Updating.
https://ojs.aaai.org/index.php/AAAI/article/view/17301

Abstract
Vertical federated learning (VFL) attracts increasing attention due to the emerging demands of multi-party collaborative modeling and concerns of privacy leakage. In the real VFL applications, usually only one or partial parties hold labels, which makes it challenging for all parties to collaboratively learn the model without privacy leakage. Meanwhile, most existing VFL algorithms are trapped in the synchronous computations, which leads to inefficiency in their real-world applications. To address these challenging problems, we propose a novel VFL framework integrated with new backward updating mechanism and bilevel asynchronous parallel architecture (VFB^2), under which three new algorithms, including VFB^2-SGD, -SVRG, and -SAGA, are proposed. We derive the theoretical results of the convergence rates of these three algorithms under both strongly convex and nonconvex conditions. We also prove the security of VFB^2 under semi-honest threat models. Extensive experiments on benchmark datasets demonstrate that our algorithms are efficient, scalable, and lossless.
				
由于多方协同建模的需求和对隐私泄露的关注，垂直联邦学习(VFL)越来越受到关注。在实际的VFL应用程序中，通常只有一个或部分方持有标签，这使得所有方在不泄露隐私的情况下协作学习模型具有挑战性。同时，现有的VFL算法大多受困于同步计算，在实际应用中效率低下。为了解决这些问题，我们提出了一种新的VFL框架，该框架集成了新的向后更新机制和两级异步并行架构(VFB^2)，并在此基础上提出了VFB^2- sgd、-SVRG和-SAGA三种新的算法。在强凸和非凸条件下，我们得到了这三种算法的收敛速度的理论结果。我们还证明了VFB^2在半诚实威胁模型下的安全性。在基准数据集上的大量实验表明，我们的算法是高效的、可扩展的和无损的。

15. A Serverless Approach to Federated Learning Infrastructure Oriented for IoT/Edge Data Sources (Student Abstract).
https://ojs.aaai.org/index.php/AAAI/article/view/17870

Abstract
The paper proposes a Serverless and Mobile relay based architecture for a highly scalable Federated Learning system for low power IoT and Edge Devices. The aim is an easily deployable infrastructure on a public cloud platform by the end user and democratize the use of federated learning.
				
本文提出了一种基于移动中继的无服务器体系结构，用于低功耗物联网和边缘设备的高可伸缩性联邦学习系统。其目标是让最终用户在公共云平台上轻松部署基础设施，并普及联邦学习的使用。
