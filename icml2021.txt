1. Debiasing Model Updates for Improving Personalized Federated Training.
http://proceedings.mlr.press/v139/acar21a.html

We propose a novel method for federated learning that is customized specifically to the objective of a given edge device. In our proposed method, a server trains a global meta-model by collaborating with devices without actually sharing data. The trained global meta-model is then personalized locally by each device to meet its specific objective. Different from the conventional federated learning setting, training customized models for each device is hindered by both the inherent data biases of the various devices, as well as the requirements imposed by the federated architecture. We propose gradient correction methods leveraging prior works, and explicitly de-bias the meta-model in the distributed heterogeneous data setting to learn personalized device models. We present convergence guarantees of our method for strongly convex, convex and nonconvex meta objectives. We empirically evaluate the performance of our method on benchmark datasets and demonstrate significant communication savings.
  
我们提出了一种新的联邦学习方法，它是专门针对给定的边缘设备的目标定制的。在我们提出的方法中，服务器通过与设备协作来训练全局元模型，而不需要实际共享数据。经过训练的全局元模型然后由每个设备在本地进行个性化，以满足其特定的目标。与传统的联邦学习设置不同，为每个设备训练定制模型受到各种设备固有的数据偏差和联邦体系结构的要求的阻碍。我们利用前人的研究成果，提出了梯度校正方法，并在分布式异构数据设置中明确地去偏置元模型，以学习个性化的设备模型。对于强凸、凸和非凸的元目标，给出了该方法的收敛性保证。我们在基准数据集上实证地评估了我们的方法的性能，并证明了显著的通信节省。

2. Federated Learning under Arbitrary Communication Patterns.
http://proceedings.mlr.press/v139/avdiukhin21a.html

Federated Learning is a distributed learning setting where the goal is to train a centralized model with training data distributed over a large number of heterogeneous clients, each with unreliable and relatively slow network connections. A common optimization approach used in federated learning is based on the idea of local SGD: each client runs some number of SGD steps locally and then the updated local models are averaged to form the updated global model on the coordinating server. In this paper, we investigate the performance of an asynchronous version of local SGD wherein the clients can communicate with the server at arbitrary time intervals. Our main result shows that for smooth strongly convex and smooth nonconvex functions we achieve convergence rates that match the synchronous version that requires all clients to communicate simultaneously.
  
Federated Learning是一种分布式学习设置，其目标是使用分布在大量异构客户机上的训练数据来训练一个集中式模型，每个客户机都具有不可靠且相对较慢的网络连接。联邦学习中使用的一种常见优化方法是基于本地SGD的思想:每个客户端在本地运行一些SGD步骤，然后对更新的本地模型求平均，在协调服务器上形成更新的全局模型。在本文中，我们研究了本地SGD的异步版本的性能，其中客户端可以在任意时间间隔与服务器通信。我们的主要结果表明，对于平滑的强凸函数和平滑的非凸函数，我们实现了与要求所有客户端同时通信的同步版本相匹配的收敛速度。

3. One for One, or All for All: Equilibria and Optimality of Collaboration in Federated Learning.
http://proceedings.mlr.press/v139/blum21a.html

In recent years, federated learning has been embraced as an approach for bringing about collaboration across large populations of learning agents. However, little is known about how collaboration protocols should take agents’ incentives into account when allocating individual resources for communal learning in order to maintain such collaborations. Inspired by game theoretic notions, this paper introduces a framework for incentive-aware learning and data sharing in federated learning. Our stable and envy-free equilibria capture notions of collaboration in the presence of agents interested in meeting their learning objectives while keeping their own sample collection burden low. For example, in an envy-free equilibrium, no agent would wish to swap their sampling burden with any other agent and in a stable equilibrium, no agent would wish to unilaterally reduce their sampling burden. In addition to formalizing this framework, our contributions include characterizing the structural properties of such equilibria, proving when they exist, and showing how they can be computed. Furthermore, we compare the sample complexity of incentive-aware collaboration with that of optimal collaboration when one ignores agents’ incentives.
  
近年来，联合学习被认为是一种跨大量学习代理实现协作的方法。然而，在为公共学习分配个人资源以维持这种协作时，协作协议应如何将代理的动机考虑在内，目前尚不清楚。受博弈论思想的启发，本文提出了一个激励意识学习和数据共享的联合学习框架。我们的稳定和无嫉妒均衡捕获了在有兴趣满足其学习目标的代理存在的情况下合作的概念，同时保持自己的样本收集负担较低。例如，在一个没有嫉妒的均衡中，没有人愿意与任何其他的人交换他们的抽样负担，而在一个稳定的均衡中，没有人愿意单方面减少他们的抽样负担。除了形式化这个框架外，我们的贡献还包括描述这种平衡的结构性质，证明它们何时存在，以及说明如何计算它们。此外，我们还比较了在忽略个体动机的情况下，动机意识协作与最优协作的样本复杂性。

4. Exploiting Shared Representations for Personalized Federated Learning.
http://proceedings.mlr.press/v139/collins21a.html

Deep neural networks have shown the ability to extract universal feature representations from data such as images and text that have been useful for a variety of learning tasks. However, the fruits of representation learning have yet to be fully-realized in federated settings. Although data in federated settings is often non-i.i.d. across clients, the success of centralized deep learning suggests that data often shares a global {\em feature representation}, while the statistical heterogeneity across clients or tasks is concentrated in the {\em labels}. Based on this intuition, we propose a novel federated learning framework and algorithm for learning a shared data representation across clients and unique local heads for each client. Our algorithm harnesses the distributed computational power across clients to perform many local-updates with respect to the low-dimensional local parameters for every update of the representation. We prove that this method obtains linear convergence to the ground-truth representation with near-optimal sample complexity in a linear setting, demonstrating that it can efficiently reduce the problem dimension for each client. Further, we provide extensive experimental results demonstrating the improvement of our method over alternative personalized federated learning approaches in heterogeneous settings.
  
深度神经网络已经显示出从图像和文本等数据中提取通用特征表示的能力，这些数据对各种学习任务都很有用。然而，表示学习的成果还没有在联邦设置中完全实现。尽管联邦设置中的数据通常不是i.i.d。在客户端之间，集中式深度学习的成功表明，数据通常共享一个全局的{em特征表示}，而客户端或任务之间的统计异质性集中在{em标签}。基于这种直觉，我们提出了一种新的联邦学习框架和算法，用于学习跨客户端共享的数据表示和每个客户端唯一的本地头。我们的算法利用客户端的分布式计算能力，在每次更新表示时，针对低维局部参数执行许多本地更新。我们证明了该方法在线性环境下，在样本复杂度接近最优的情况下，对地面真实表示具有线性收敛性，证明了该方法能够有效地降低每个客户端的问题维数。此外，我们提供了大量的实验结果，证明了在异构环境下，我们的方法比其他个性化联合学习方法的改进。

5. Heterogeneity for the Win: One-Shot Federated Clustering.
http://proceedings.mlr.press/v139/dennis21a.html

In this work, we explore the unique challenges—and opportunities—of unsupervised federated learning (FL). We develop and analyze a one-shot federated clustering scheme, kfed, based on the widely-used Lloyd’s method for $k$-means clustering. In contrast to many supervised problems, we show that the issue of statistical heterogeneity in federated networks can in fact benefit our analysis. We analyse kfed under a center separation assumption and compare it to the best known requirements of its centralized counterpart. Our analysis shows that in heterogeneous regimes where the number of clusters per device $(k’)$ is smaller than the total number of clusters over the network $k$, $(k’\le \sqrt{k})$, we can use heterogeneity to our advantage—significantly weakening the cluster separation requirements for kfed. From a practical viewpoint, kfed also has many desirable properties: it requires only round of communication, can run asynchronously, and can handle partial participation or node/network failures. We motivate our analysis with experiments on common FL benchmarks, and highlight the practical utility of one-shot clustering through use-cases in personalized FL and device sampling.
  
在这项工作中，我们探索了非监督联合学习(FL)的独特挑战和机遇。在广泛使用的$k$均值聚类方法的基础上，我们开发并分析了一种一次性联邦聚类方案kfed。与许多监督问题相比，我们表明联邦网络中的统计异质性问题实际上有利于我们的分析。我们在中心分离假设下分析kfed，并将其与最著名的集中式需求进行比较。我们的分析表明，在异构系统中，当每个设备的集群数目$(k ')$小于网络上的集群总数$k$， $(k ' \le \sqrt{k})$时，我们可以充分利用异构性——这大大削弱了kfed的集群分离需求。从实践的角度来看，kfed还有许多可取的特性:它只需要一轮通信，可以异步运行，并且可以处理部分参与或节点/网络故障。我们通过对常见FL基准的实验来激励我们的分析，并通过个性化FL和设备采样的用例来强调一次性聚类的实用价值。

6. Clustered Sampling: Low-Variance and Improved Representativity for Clients Selection in Federated Learning.
http://proceedings.mlr.press/v139/fraboni21a.html

This work addresses the problem of optimizing communications between server and clients in federated learning (FL). Current sampling approaches in FL are either biased, or non optimal in terms of server-clients communications and training stability. To overcome this issue, we introduce clustered sampling for clients selection. We prove that clustered sampling leads to better clients representatitivity and to reduced variance of the clients stochastic aggregation weights in FL. Compatibly with our theory, we provide two different clustering approaches enabling clients aggregation based on 1) sample size, and 2) models similarity. Through a series of experiments in non-iid and unbalanced scenarios, we demonstrate that model aggregation through clustered sampling consistently leads to better training convergence and variability when compared to standard sampling approaches. Our approach does not require any additional operation on the clients side, and can be seamlessly integrated in standard FL implementations. Finally, clustered sampling is compatible with existing methods and technologies for privacy enhancement, and for communication reduction through model compression.
  
本工作解决了联邦学习(FL)中服务器和客户端的通信优化问题。目前FL中的采样方法要么有偏差，要么在服务器-客户端通信和训练稳定性方面不是最优的。为了解决这个问题，我们引入了聚类抽样来选择客户。我们证明了聚类抽样可以提高客户的代表性，并降低FL中客户随机聚集权重的方差。与我们的理论相兼容，我们提供了两种不同的聚类方法，使客户能够基于1)样本大小和2)模型相似性进行聚集。通过在非iid和非平衡场景下的一系列实验，我们证明，与标准采样方法相比，通过聚类采样的模型聚合始终能够获得更好的训练收敛性和可变性。我们的方法不需要在客户端进行任何额外的操作，并且可以无缝地集成在标准的FL实现中。最后，集群采样与现有的隐私增强方法和技术兼容，并通过模型压缩减少通信。

7. Federated Learning of User Verification Models Without Sharing Embeddings.
http://proceedings.mlr.press/v139/hosseini21a.html

We consider the problem of training User Verification (UV) models in federated setup, where each user has access to the data of only one class and user embeddings cannot be shared with the server or other users. To address this problem, we propose Federated User Verification (FedUV), a framework in which users jointly learn a set of vectors and maximize the correlation of their instance embeddings with a secret linear combination of those vectors. We show that choosing the linear combinations from the codewords of an error-correcting code allows users to collaboratively train the model without revealing their embedding vectors. We present the experimental results for user verification with voice, face, and handwriting data and show that FedUV is on par with existing approaches, while not sharing the embeddings with other users or the server.
  
我们在联邦设置中考虑了训练用户验证(UV)模型的问题，其中每个用户只能访问一个类的数据，用户嵌入不能与服务器或其他用户共享。为了解决这个问题，我们提出了联邦用户验证(FedUV)框架，在这个框架中，用户共同学习一组向量，并通过这些向量的秘密线性组合最大化他们的实例嵌入的相关性。我们表明，从纠错码的码字中选择线性组合允许用户协作训练模型，而不揭示他们的嵌入向量。我们给出了使用语音、人脸和手写数据进行用户验证的实验结果，表明FedUV与现有的方法相当，而不与其他用户或服务器共享嵌入结果。

8. FL-NTK: A Neural Tangent Kernel-based Framework for Federated Learning Analysis.
http://proceedings.mlr.press/v139/huang21c.html

Federated Learning (FL) is an emerging learning scheme that allows different distributed clients to train deep neural networks together without data sharing. Neural networks have become popular due to their unprecedented success. To the best of our knowledge, the theoretical guarantees of FL concerning neural networks with explicit forms and multi-step updates are unexplored. Nevertheless, training analysis of neural networks in FL is non-trivial for two reasons: first, the objective loss function we are optimizing is non-smooth and non-convex, and second, we are even not updating in the gradient direction. Existing convergence results for gradient descent-based methods heavily rely on the fact that the gradient direction is used for updating. The current paper presents a new class of convergence analysis for FL, Federated Neural Tangent Kernel (FL-NTK), which corresponds to overparamterized ReLU neural networks trained by gradient descent in FL and is inspired by the analysis in Neural Tangent Kernel (NTK). Theoretically, FL-NTK converges to a global-optimal solution at a linear rate with properly tuned learning parameters. Furthermore, with proper distributional assumptions, FL-NTK can also achieve good generalization. The proposed theoretical analysis scheme can be generalized to more complex neural networks.
  
联邦学习(FL)是一种新兴的学习方案，它允许不同的分布式客户端在不共享数据的情况下一起训练深度神经网络。神经网络因其前所未有的成功而变得流行起来。就我们所知，对于具有显式形式和多步更新的神经网络，FL的理论保证尚未被探索。然而，在FL中对神经网络的训练分析是不平凡的，原因有二:一是我们优化的目标损失函数是非光滑非凸的，二是我们甚至没有在梯度方向上进行更新。现有的梯度下降法的收敛结果很大程度上依赖于梯度方向的更新。本文提出了一种新的神经网络收敛分析方法——联邦神经切线核(Federated Neural Tangent Kernel, FL-NTK)，该方法对应于用梯度下降法训练的过参数化的ReLU神经网络，并受到神经切线核(Neural tan Kernel, NTK)分析方法的启发。理论上，FL-NTK在适当调整学习参数的情况下，以线性速度收敛到全局最优解。此外，在合理的分布假设下，FL-NTK也可以实现良好的泛化。所提出的理论分析方案可以推广到更复杂的神经网络。

9. The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation.
http://proceedings.mlr.press/v139/kairouz21a.html

We consider training models on private data that are distributed across user devices. To ensure privacy, we add on-device noise and use secure aggregation so that only the noisy sum is revealed to the server. We present a comprehensive end-to-end system, which appropriately discretizes the data and adds discrete Gaussian noise before performing secure aggregation. We provide a novel privacy analysis for sums of discrete Gaussians and carefully analyze the effects of data quantization and modular summation arithmetic. Our theoretical guarantees highlight the complex tension between communication, privacy, and accuracy. Our extensive experimental results demonstrate that our solution is essentially able to match the accuracy to central differential privacy with less than 16 bits of precision per value.

我们考虑在跨用户设备分布的私有数据上建立训练模型。为了确保隐私，我们添加了设备上的噪声，并使用安全的聚合，以便只有噪声和显示给服务器。我们提出了一个完整的端到端系统，在执行安全聚合之前适当地离散数据并添加离散高斯噪声。我们提供了一种新的离散高斯和的隐私分析方法，并仔细分析了数据量化和模求和算法的影响。我们的理论保证突出了通信、隐私和准确性之间复杂的紧张关系。我们广泛的实验结果表明，我们的解决方案基本上能够与中心差分隐私的精度匹配，每个值的精度小于16位。

10. Gradient Disaggregation: Breaking Privacy in Federated Learning by Reconstructing the User Participant Matrix.
http://proceedings.mlr.press/v139/lam21b.html

We show that aggregated model updates in federated learning may be insecure. An untrusted central server may disaggregate user updates from sums of updates across participants given repeated observations, enabling the server to recover privileged information about individual users’ private training data via traditional gradient inference attacks. Our method revolves around reconstructing participant information (e.g: which rounds of training users participated in) from aggregated model updates by leveraging summary information from device analytics commonly used to monitor, debug, and manage federated learning systems. Our attack is parallelizable and we successfully disaggregate user updates on settings with up to thousands of participants. We quantitatively and qualitatively demonstrate significant improvements in the capability of various inference attacks on the disaggregated updates. Our attack enables the attribution of learned properties to individual users, violating anonymity, and shows that a determined central server may undermine the secure aggregation protocol to break individual users’ data privacy in federated learning.
  
我们证明了联合学习中的聚合模型更新可能是不安全的。一个不可信的中心服务器可能会将用户的更新从重复观察的参与者的更新总数中分解出来，从而使服务器能够通过传统的梯度推理攻击恢复关于个人用户私人训练数据的特权信息。我们的方法围绕着从聚合模型更新中重建参与者信息(例如:用户参与了哪轮培训)，通过利用设备分析的摘要信息，通常用于监控、调试和管理联邦学习系统。我们的攻击是可并行的，我们成功地分解了多达数千名参与者的设置上的用户更新。我们在定量和定性上证明了对分类更新的各种推理攻击能力的显著改进。我们的攻击使学习到的属性归属于个人用户，违反了匿名性，并表明一个坚定的中央服务器可能破坏安全聚合协议，从而在联邦学习中破坏个人用户的数据隐私。

11. Ditto: Fair and Robust Federated Learning Through Personalization.
http://proceedings.mlr.press/v139/li21h.html

Fairness and robustness are two important concerns for federated learning systems. In this work, we identify that robustness to data and model poisoning attacks and fairness, measured as the uniformity of performance across devices, are competing constraints in statistically heterogeneous networks. To address these constraints, we propose employing a simple, general framework for personalized federated learning, Ditto, that can inherently provide fairness and robustness benefits, and develop a scalable solver for it. Theoretically, we analyze the ability of Ditto to achieve fairness and robustness simultaneously on a class of linear problems. Empirically, across a suite of federated datasets, we show that Ditto not only achieves competitive performance relative to recent personalization methods, but also enables more accurate, robust, and fair models relative to state-of-the-art fair or robust baselines.

公平性和鲁棒性是联邦学习系统的两个重要问题。在这项工作中，我们确定对数据和模型中毒攻击的鲁棒性和公平性(衡量设备间性能的一致性)是统计异构网络中相互竞争的约束条件。为了解决这些限制，我们提出使用一个简单的、通用的个性化联合学习框架Ditto，它可以提供内在的公平性和鲁棒性好处，并为它开发一个可伸缩的求解器。从理论上分析了Ditto算法对一类线性问题同时实现公平性和鲁棒性的能力。根据经验，在一组联邦数据集中，我们表明，Ditto不仅实现了相对于最近的个性化方法具有竞争力的性能，而且还实现了相对于最先进的公平或稳健基线更准确、稳健和公平的模型。

12. Bias-Variance Reduced Local SGD for Less Heterogeneous Federated Learning.
http://proceedings.mlr.press/v139/murata21a.html

Recently, local SGD has got much attention and been extensively studied in the distributed learning community to overcome the communication bottleneck problem. However, the superiority of local SGD to minibatch SGD only holds in quite limited situations. In this paper, we study a new local algorithm called Bias-Variance Reduced Local SGD (BVR-L-SGD) for nonconvex distributed optimization. Algorithmically, our proposed bias and variance reduced local gradient estimator fully utilizes small second-order heterogeneity of local objectives and suggests randomly picking up one of the local models instead of taking the average of them when workers are synchronized. Theoretically, under small heterogeneity of local objectives, we show that BVR-L-SGD achieves better communication complexity than both the previous non-local and local methods under mild conditions, and particularly BVR-L-SGD is the first method that breaks the barrier of communication complexity $\Theta(1/\varepsilon)$ for general nonconvex smooth objectives when the heterogeneity is small and the local computation budget is large. Numerical results are given to verify the theoretical findings and give empirical evidence of the superiority of our method.
  
最近，在分布式学习社区中，局部SGD得到了广泛的关注和研究，以克服通信瓶颈问题。然而，本地SGD相对于小批量SGD的优势只存在于相当有限的情况下。本文研究了一种新的非凸分布优化局部算法BVR-L-SGD (Bias-Variance Reduced local SGD)。在算法上，我们提出的偏差和方差降低了局部梯度估计，充分利用了局部目标的二阶异质性，并建议在工作同步时随机选取一个局部模型，而不是取它们的平均值。理论上，在局部目标异质性较小的情况下，我们证明了BVR-L-SGD在温和条件下比之前的非局部和局部方法获得了更好的通信复杂度，特别是BVR-L-SGD对于非凸平滑目标，在异构性较小时，局部计算量较大时，是第一个突破通信复杂度$ Theta(1/ varepsilon)$障碍的方法。数值结果验证了理论结果，并证明了该方法的优越性。

13. Personalized Federated Learning using Hypernetworks.
http://proceedings.mlr.press/v139/shamsian21a.html

Personalized federated learning is tasked with training machine learning models for multiple clients, each with its own data distribution. The goal is to train personalized models collaboratively while accounting for data disparities across clients and reducing communication costs. We propose a novel approach to this problem using hypernetworks, termed pFedHN for personalized Federated HyperNetworks. In this approach, a central hypernetwork model is trained to generate a set of models, one model for each client. This architecture provides effective parameter sharing across clients while maintaining the capacity to generate unique and diverse personal models. Furthermore, since hypernetwork parameters are never transmitted, this approach decouples the communication cost from the trainable model size. We test pFedHN empirically in several personalized federated learning challenges and find that it outperforms previous methods. Finally, since hypernetworks share information across clients, we show that pFedHN can generalize better to new clients whose distributions differ from any client observed during training.
  
个性化联合学习的任务是为多个客户训练机器学习模型，每个客户都有自己的数据分布。其目标是协同训练个性化模型，同时考虑到客户之间的数据差异，并降低沟通成本。我们提出了一种利用超网络解决这一问题的新方法，称为pFedHN的个性化联邦超网络。在这种方法中，中央超网络模型被训练成生成一组模型，每个客户端一个模型。该架构在客户端之间提供了有效的参数共享，同时保持了生成独特和多样化的个人模型的能力。此外，由于超网络参数从不传输，该方法将通信开销与可训练模型大小解耦。我们在几个个性化的联合学习挑战中对pFedHN进行了经验测试，发现它的性能优于以往的方法。最后，由于超网络在客户端之间共享信息，我们证明pFedHN可以更好地推广到新客户端，这些新客户端的分布与训练期间观察到的任何客户端都不同。

14. CRFL: Certifiably Robust Federated Learning against Backdoor Attacks.
http://proceedings.mlr.press/v139/xie21a.html

Federated Learning (FL) as a distributed learning paradigm that aggregates information from diverse clients to train a shared global model, has demonstrated great success. However, malicious clients can perform poisoning attacks and model replacement to introduce backdoors into the trained global model. Although there have been intensive studies designing robust aggregation methods and empirical robust federated training protocols against backdoors, existing approaches lack robustness certification. This paper provides the first general framework, Certifiably Robust Federated Learning (CRFL), to train certifiably robust FL models against backdoors. Our method exploits clipping and smoothing on model parameters to control the global model smoothness, which yields a sample-wise robustness certification on backdoors with limited magnitude. Our certification also specifies the relation to federated learning parameters, such as poisoning ratio on instance level, number of attackers, and training iterations. Practically, we conduct comprehensive experiments across a range of federated datasets, and provide the first benchmark for certified robustness against backdoor attacks in federated learning. Our code is publicaly available at https://github.com/AI-secure/CRFL.
  
Federated Learning (FL)作为一种分布式学习范式，通过聚合来自不同客户端的信息来训练一个共享的全局模型，已经取得了巨大的成功。然而，恶意客户端可以进行投毒攻击和模型替换，将后门引入训练有素的全局模型。尽管针对后门的鲁棒聚集方法和经验鲁棒联邦训练协议的设计已经进行了深入的研究，但现有的方法缺乏鲁棒性认证。本文提供了第一个通用框架，认证鲁棒联邦学习(CRFL)，以训练认证鲁棒的FL模型对抗后门。我们的方法利用裁剪和平滑模型参数来控制全局模型的平滑性，从而在有限的幅度下获得了对后门的样本鲁棒性认证。我们的认证还指定了与联邦学习参数的关系，例如实例级别上的中毒比率、攻击者的数量和训练迭代。在实践中，我们对一系列联邦数据集进行了全面的实验，并为联邦学习中对后门攻击的鲁棒性认证提供了第一个基准。我们的代码可以在https://github.com/AI-secure/CRFL公开获得。

15. Federated Continual Learning with Weighted Inter-client Transfer.
http://proceedings.mlr.press/v139/yoon21b.html

There has been a surge of interest in continual learning and federated learning, both of which are important in deep neural networks in real-world scenarios. Yet little research has been done regarding the scenario where each client learns on a sequence of tasks from a private local data stream. This problem of federated continual learning poses new challenges to continual learning, such as utilizing knowledge from other clients, while preventing interference from irrelevant knowledge. To resolve these issues, we propose a novel federated continual learning framework, Federated Weighted Inter-client Transfer (FedWeIT), which decomposes the network weights into global federated parameters and sparse task-specific parameters, and each client receives selective knowledge from other clients by taking a weighted combination of their task-specific parameters. FedWeIT minimizes interference between incompatible tasks, and also allows positive knowledge transfer across clients during learning. We validate our FedWeIT against existing federated learning and continual learning methods under varying degrees of task similarity across clients, and our model significantly outperforms them with a large reduction in the communication cost.
  
人们对持续学习和联合学习的兴趣激增，这两种学习在现实场景中的深度神经网络中都很重要。然而，关于每个客户端从私有本地数据流学习一系列任务的场景的研究很少。这种联合持续学习的问题对持续学习提出了新的挑战，例如利用来自其他客户的知识，同时防止不相干知识的干扰。为了解决这些问题，我们提出了一种新的联邦持续学习框架——联邦加权客户机间传输(federweit)，该框架将网络权值分解为全局联邦参数和稀疏任务特定参数，每个客户通过对他们的特定任务参数进行加权组合，从其他客户那里获得选择性的知识。FedWeIT最大限度地减少了不兼容任务之间的干扰，并允许在学习过程中跨客户进行积极的知识转移。在不同程度的任务相似度下，我们将FedWeIT与现有的联合学习和持续学习方法进行了对比验证，我们的模型在大大降低通信成本的情况下显著优于它们。

16. Federated Deep AUC Maximization for Hetergeneous Data with a Constant Communication Complexity.
http://proceedings.mlr.press/v139/yuan21a.html

Deep AUC (area under the ROC curve) Maximization (DAM) has attracted much attention recently due to its great potential for imbalanced data classification. However, the research on Federated Deep AUC Maximization (FDAM) is still limited. Compared with standard federated learning (FL) approaches that focus on decomposable minimization objectives, FDAM is more complicated due to its minimization objective is non-decomposable over individual examples. In this paper, we propose improved FDAM algorithms for heterogeneous data by solving the popular non-convex strongly-concave min-max formulation of DAM in a distributed fashion, which can also be applied to a class of non-convex strongly-concave min-max problems. A striking result of this paper is that the communication complexity of the proposed algorithm is a constant independent of the number of machines and also independent of the accuracy level, which improves an existing result by orders of magnitude. The experiments have demonstrated the effectiveness of our FDAM algorithm on benchmark datasets, and on medical chest X-ray images from different organizations. Our experiment shows that the performance of FDAM using data from multiple hospitals can improve the AUC score on testing data from a single hospital for detecting life-threatening diseases based on chest radiographs.
  
Deep AUC (area under ROC curve) Maximization (DAM)因其在不平衡数据分类方面的巨大潜力而备受关注。然而，关于联邦深度AUC最大化(FDAM)的研究还很有限。与专注于可分解的最小化目标的标准联邦学习(FL)方法相比，FDAM由于其最小化目标在单个例子上是不可分解的，所以更加复杂。在本文中，我们提出了一种针对异构数据的改进的FDAM算法，该算法以分布式的方式求解了流行的非凸强凹最小值问题的DAM公式，该公式也可以应用于一类非凸强凹最小值问题。本文的一个显著结果是，提出的算法的通信复杂度是一个常数，与机器的数量无关，也与精度水平无关，这将现有的结果改进了一个数量级。实验证明了该算法在基准数据集和不同组织的医用胸部x线图像上的有效性。实验表明，采用多家医院数据的FDAM可以提高单家医院基于胸片检测危重疾病的检测数据的AUC评分。

17. Federated Composite Optimization.
http://proceedings.mlr.press/v139/yuan21d.html

Federated Learning (FL) is a distributed learning paradigm that scales on-device learning collaboratively and privately. Standard FL algorithms such as FEDAVG are primarily geared towards smooth unconstrained settings. In this paper, we study the Federated Composite Optimization (FCO) problem, in which the loss function contains a non-smooth regularizer. Such problems arise naturally in FL applications that involve sparsity, low-rank, monotonicity, or more general constraints. We first show that straightforward extensions of primal algorithms such as FedAvg are not well-suited for FCO since they suffer from the "curse of primal averaging," resulting in poor convergence. As a solution, we propose a new primal-dual algorithm, Federated Dual Averaging (FedDualAvg), which by employing a novel server dual averaging procedure circumvents the curse of primal averaging. Our theoretical analysis and empirical experiments demonstrate that FedDualAvg outperforms the other baselines.
  
联合学习(FL)是一种分布式学习范式，可以在设备上协作和私下地扩展学习。标准的FL算法，如FEDAVG，主要是面向平滑的无约束设置。在本文中，我们研究了联邦复合优化(FCO)问题，其中损失函数包含一个非光滑正则化。在涉及稀疏性、低秩、单调性或更一般约束的FL应用中，这些问题自然会出现。我们首先表明，原始算法的直接扩展，如FedAvg，并不非常适合FCO，因为它们遭受“原始平均诅咒”，导致较差的收敛性。作为一种解决方案，我们提出了一种新的原始-对偶算法——联邦双重平均(federdualavg)，该算法采用了一种新的服务器双重平均过程，绕过了原始平均的诅咒。我们的理论分析和实证实验表明，FedDualAvg优于其他基线。

18. Data-Free Knowledge Distillation for Heterogeneous Federated Learning.
http://proceedings.mlr.press/v139/zhu21b.html

Federated Learning (FL) is a decentralized machine-learning paradigm, in which a global server iteratively averages the model parameters of local users without accessing their data. User heterogeneity has imposed significant challenges to FL, which can incur drifted global models that are slow to converge. Knowledge Distillation has recently emerged to tackle this issue, by refining the server model using aggregated knowledge from heterogeneous users, other than directly averaging their model parameters. This approach, however, depends on a proxy dataset, making it impractical unless such a prerequisite is satisfied. Moreover, the ensemble knowledge is not fully utilized to guide local model learning, which may in turn affect the quality of the aggregated model. Inspired by the prior art, we propose a data-free knowledge distillation approach to address heterogeneous FL, where the server learns a lightweight generator to ensemble user information in a data-free manner, which is then broadcasted to users, regulating local training using the learned knowledge as an inductive bias. Empirical studies powered by theoretical implications show that our approach facilitates FL with better generalization performance using fewer communication rounds, compared with the state-of-the-art.
  
联邦学习(FL)是一种分散的机器学习模式，在这种模式中，全局服务器迭代地平均本地用户的模型参数，而不访问他们的数据。用户异构性给FL带来了重大挑战，这可能导致漂移的全球模型收敛缓慢。最近出现的Knowledge蒸馏方法解决了这个问题，它使用来自异构用户的聚合知识来细化服务器模型，而不是直接平均他们的模型参数。然而，这种方法依赖于代理数据集，因此除非满足这样的先决条件，否则它是不切实际的。此外，集成知识没有被充分利用来指导局部模型学习，进而影响聚合模型的质量。受现有技术的启发，我们提出了一种无数据知识蒸馏方法来解决异构FL，其中服务器学习一个轻量级生成器，以无数据的方式集成用户信息，然后将这些信息广播给用户，利用学习到的知识作为归纳偏差调节局部训练。基于理论启示的实证研究表明，与目前最先进的方法相比，我们的方法具有更好的泛化性能，使用更少的通信轮。
